{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8b2e392",
   "metadata": {},
   "source": [
    "__Exercise -1: Data Cleaning and Pre-processing__<br><nr>\n",
    "Dataset provided is foodgrainsproduction_fiscalyear.csv<br>\n",
    "This dataset contains a data on total production of various grains in Nepal during various fiscal year. Using\n",
    "the dataset complete the following tasks:<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda85f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39eb5ed",
   "metadata": {},
   "source": [
    "__Task1: Handling Special Characters and Missing Values__\n",
    "1. Load the dataset into a Pandas Data-frame.\n",
    "2. Replace special characters and non-numeric values with \"NaN\".\n",
    "3. Fill missing values with appropriate methods(forward fill, median replacement or drop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73af9312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F/Y</th>\n",
       "      <th>Paddy</th>\n",
       "      <th>Maize</th>\n",
       "      <th>Wheat</th>\n",
       "      <th>Millet</th>\n",
       "      <th>Barley</th>\n",
       "      <th>Buckwheat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>3710</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>1086</td>\n",
       "      <td>291</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>4030</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>1184</td>\n",
       "      <td>295</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>4216</td>\n",
       "      <td>1484.0</td>\n",
       "      <td>1158</td>\n",
       "      <td>283</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>$$$$</td>\n",
       "      <td>1511.0</td>\n",
       "      <td>%%%%%</td>\n",
       "      <td>283</td>\n",
       "      <td>&amp;&amp;&amp;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>4133</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>1344</td>\n",
       "      <td>283</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F/Y Paddy   Maize  Wheat Millet Barley  Buckwheat\n",
       "0  1998  3710  1346.0   1086    291     32        NaN\n",
       "1  1999  4030  1445.0   1184    295     31        NaN\n",
       "2  2000  4216  1484.0   1158    283     30        NaN\n",
       "3  2001  $$$$  1511.0  %%%%%    283    &&&        NaN\n",
       "4  2002  4133  1569.0   1344    283     32        NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('foodgrainsproduction_fiscalyear.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dedbfc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F/Y Paddy   Maize  Wheat Millet Barley  Buckwheat\n",
      "0   1998  3710  1346.0   1086    291     32        NaN\n",
      "1   1999  4030  1445.0   1184    295     31        NaN\n",
      "2   2000  4216  1484.0   1158    283     30        NaN\n",
      "3   2001  $$$$  1511.0  %%%%%    283    &&&        NaN\n",
      "4   2002  4133  1569.0   1344    283     32        NaN\n",
      "5   2003  4456     NaN   1387    283     28        NaN\n",
      "6   2004  4290  1716.0   1442    app     29        NaN\n",
      "7   2005  4209  1734.0   1394    291     28        NaN\n",
      "8   2006   NaN  1820.0   1515    285    (((        NaN\n",
      "9   2007  4299     NaN   1572    291     28        NaN\n",
      "10  2008  4524  1931.0   1344    293     23        NaN\n",
      "11  2009  4023  1855.0    NaN    300     28        NaN\n",
      "12  2010  $$$$  2067.0   1746    app     30        9.0\n",
      "13  2011  5072  2179.0   1846   3151     35       10.0\n",
      "14  2012  4505  1999.0   1727   3055     34       10.0\n",
      "15  2004  4290  1716.0   1442    app     29        NaN\n",
      "16  2005  4209  1734.0   1394    291     28        NaN\n",
      "17  2006   NaN  1820.0   1515    285    (((        NaN\n"
     ]
    }
   ],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60eb6866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F/Y Paddy   Maize Wheat Millet Barley  Buckwheat\n",
      "0   1998  3710  1346.0  1086    291     32        NaN\n",
      "1   1999  4030  1445.0  1184    295     31        NaN\n",
      "2   2000  4216  1484.0  1158    283     30        NaN\n",
      "3   2001   NaN  1511.0   NaN    283    NaN        NaN\n",
      "4   2002  4133  1569.0  1344    283     32        NaN\n",
      "5   2003  4456     NaN  1387    283     28        NaN\n",
      "6   2004  4290  1716.0  1442    NaN     29        NaN\n",
      "7   2005  4209  1734.0  1394    291     28        NaN\n",
      "8   2006   NaN  1820.0  1515    285    NaN        NaN\n",
      "9   2007  4299     NaN  1572    291     28        NaN\n",
      "10  2008  4524  1931.0  1344    293     23        NaN\n",
      "11  2009  4023  1855.0   NaN    300     28        NaN\n",
      "12  2010   NaN  2067.0  1746    NaN     30        9.0\n",
      "13  2011  5072  2179.0  1846   3151     35       10.0\n",
      "14  2012  4505  1999.0  1727   3055     34       10.0\n",
      "15  2004  4290  1716.0  1442    NaN     29        NaN\n",
      "16  2005  4209  1734.0  1394    291     28        NaN\n",
      "17  2006   NaN  1820.0  1515    285    NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "df1.replace(to_replace=r'[^\\d.]+', value=np.nan, regex=True, inplace=True)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b121c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F/Y Paddy   Maize Wheat Millet Barley  Buckwheat\n",
      "0   1998  3710  1346.0  1086    291     32        NaN\n",
      "1   1999  4030  1445.0  1184    295     31        NaN\n",
      "2   2000  4216  1484.0  1158    283     30        NaN\n",
      "3   2001  4216  1511.0  1158    283     30        NaN\n",
      "4   2002  4133  1569.0  1344    283     32        NaN\n",
      "5   2003  4456  1569.0  1387    283     28        NaN\n",
      "6   2004  4290  1716.0  1442    283     29        NaN\n",
      "7   2005  4209  1734.0  1394    291     28        NaN\n",
      "8   2006  4209  1820.0  1515    285     28        NaN\n",
      "9   2007  4299  1820.0  1572    291     28        NaN\n",
      "10  2008  4524  1931.0  1344    293     23        NaN\n",
      "11  2009  4023  1855.0  1344    300     28        NaN\n",
      "12  2010  4023  2067.0  1746    300     30        9.0\n",
      "13  2011  5072  2179.0  1846   3151     35       10.0\n",
      "14  2012  4505  1999.0  1727   3055     34       10.0\n",
      "15  2004  4290  1716.0  1442   3055     29       10.0\n",
      "16  2005  4209  1734.0  1394    291     28       10.0\n",
      "17  2006  4209  1820.0  1515    285     28       10.0\n"
     ]
    }
   ],
   "source": [
    "df1.ffill(inplace=True)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a25c41e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     F/Y Paddy   Maize Wheat Millet Barley  Buckwheat\n",
      "0   1998  3710  1346.0  1086    291     32        9.0\n",
      "1   1999  4030  1445.0  1184    295     31        9.0\n",
      "2   2000  4216  1484.0  1158    283     30        9.0\n",
      "3   2001  4216  1511.0  1158    283     30        9.0\n",
      "4   2002  4133  1569.0  1344    283     32        9.0\n",
      "5   2003  4456  1569.0  1387    283     28        9.0\n",
      "6   2004  4290  1716.0  1442    283     29        9.0\n",
      "7   2005  4209  1734.0  1394    291     28        9.0\n",
      "8   2006  4209  1820.0  1515    285     28        9.0\n",
      "9   2007  4299  1820.0  1572    291     28        9.0\n",
      "10  2008  4524  1931.0  1344    293     23        9.0\n",
      "11  2009  4023  1855.0  1344    300     28        9.0\n",
      "12  2010  4023  2067.0  1746    300     30        9.0\n",
      "13  2011  5072  2179.0  1846   3151     35       10.0\n",
      "14  2012  4505  1999.0  1727   3055     34       10.0\n",
      "15  2004  4290  1716.0  1442   3055     29       10.0\n",
      "16  2005  4209  1734.0  1394    291     28       10.0\n",
      "17  2006  4209  1820.0  1515    285     28       10.0\n"
     ]
    }
   ],
   "source": [
    "df1.bfill(inplace = True)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21adbb1",
   "metadata": {},
   "source": [
    "__Task2: Checking and Dropping Duplicate Values__\n",
    "1. Check for duplicate rows if found drop any duplicate rows.\n",
    "2. Verify that all duplicates have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "507a16d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7     False\n",
       "8     False\n",
       "9     False\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13    False\n",
       "14    False\n",
       "15    False\n",
       "16    False\n",
       "17    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b15b41",
   "metadata": {},
   "source": [
    "__Task3: Checking for Outliers__\n",
    "1. Identify outliers in the numerical columns using the IQR method.\n",
    "2. Remove rows if identified as outliers.\n",
    "3. Convert columns to numeric values if not already numeric and ensure all numerical data is within\n",
    "realistic ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7b204dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning:\n",
      "      F/Y  Paddy   Maize  Wheat  Millet  Barley  Buckwheat\n",
      "1   1999   4030  1445.0   1184     295      31        9.0\n",
      "2   2000   4216  1484.0   1158     283      30        9.0\n",
      "3   2001   4216  1511.0   1158     283      30        9.0\n",
      "4   2002   4133  1569.0   1344     283      32        9.0\n",
      "5   2003   4456  1569.0   1387     283      28        9.0\n",
      "6   2004   4290  1716.0   1442     283      29        9.0\n",
      "7   2005   4209  1734.0   1394     291      28        9.0\n",
      "8   2006   4209  1820.0   1515     285      28        9.0\n",
      "9   2007   4299  1820.0   1572     291      28        9.0\n",
      "11  2009   4023  1855.0   1344     300      28        9.0\n",
      "12  2010   4023  2067.0   1746     300      30        9.0\n",
      "16  2005   4209  1734.0   1394     291      28       10.0\n",
      "17  2006   4209  1820.0   1515     285      28       10.0\n",
      "Data with outliers:\n",
      "      F/Y  Paddy   Maize  Wheat  Millet  Barley  Buckwheat\n",
      "0   1998   3710  1346.0   1086     291      32        9.0\n",
      "10  2008   4524  1931.0   1344     293      23        9.0\n",
      "13  2011   5072  2179.0   1846    3151      35       10.0\n",
      "14  2012   4505  1999.0   1727    3055      34       10.0\n",
      "15  2004   4290  1716.0   1442    3055      29       10.0\n"
     ]
    }
   ],
   "source": [
    "df1 = df1.apply(pd.to_numeric, errors='coerce')\n",
    "def identify_and_handle_outliers(df):\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = (df < lower_bound) | (df > upper_bound)\n",
    "    cleaned_df = df[~outliers.any(axis=1)]\n",
    "    outliers_df = df[outliers.any(axis=1)]\n",
    "    return cleaned_df, outliers_df\n",
    "\n",
    "df1, outliers = identify_and_handle_outliers(df1)\n",
    "print('Data after cleaning:\\n',df1)\n",
    "print(\"Data with outliers:\\n\", outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "354b259a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13 entries, 1 to 17\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   F/Y        13 non-null     int64  \n",
      " 1   Paddy      13 non-null     int64  \n",
      " 2   Maize      13 non-null     float64\n",
      " 3   Wheat      13 non-null     int64  \n",
      " 4   Millet     13 non-null     int64  \n",
      " 5   Barley     13 non-null     int64  \n",
      " 6   Buckwheat  13 non-null     float64\n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 832.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2661412",
   "metadata": {},
   "source": [
    "__Exercise -2: Data Wrangling with Pandas__<br>\n",
    "To complete this exercise you will need to have following collections of dataset:\n",
    "1. Dataset1: customer_data.csv\n",
    "2. Dataset2: product_data.csv\n",
    "3. Dataset3: sales_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeb7f32",
   "metadata": {},
   "source": [
    "__Task1: Data Loading and Cleaning__\n",
    "1. Load all three datasets into Pandas Data-frames.\n",
    "2. Check for missing values and handle them appropriately.\n",
    "3. Convert the ”OrderDate” and ”CustomerSince” columns to datetime format.\n",
    "4. Check and remove any duplicate if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6c5934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('customer_data.csv')\n",
    "df3 = pd.read_csv('product_data.csv')\n",
    "df4 = pd.read_csv('sales_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "838be8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer data:\n",
      "    Years of Service  Total Assets (Millions)\n",
      "0                13                    20.59\n",
      "1                 6                     8.24\n",
      "2                 1                    10.08\n",
      "3                 4                    29.00\n",
      "4                12                    18.07\n",
      "\n",
      "Product data:\n",
      "   ProductID ProductName Category\n",
      "0     P0001   Product_1  Clothes\n",
      "1     P0002   Product_2  Clothes\n",
      "2     P0003   Product_3  Grocery\n",
      "3     P0004   Product_4     Home\n",
      "4     P0005   Product_5  Grocery\n",
      "\n",
      "Sales data:\n",
      "   OrderID CustomerID ProductID  Quantity   Price            OrderDate\n",
      "0  O00001      C0066     P0042        13  194.30  2021-01-12 15:57:26\n",
      "1  O00002      C0058     P0050        14  253.92  2022-05-04 06:23:35\n",
      "2  O00003      C0028     P0027        12   49.93  2020-02-17 23:00:30\n",
      "3  O00004      C0078     P0022        14  102.03  2020-02-24 03:50:25\n",
      "4  O00005      C0003     P0001         5  182.74  2022-04-16 15:35:10\n"
     ]
    }
   ],
   "source": [
    "print('Customer data:\\n',df2.head())\n",
    "print('\\nProduct data:\\n',df3.head())\n",
    "print('\\nSales data:\\n', df4.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4378f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 2 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Years of Service         200 non-null    int64  \n",
      " 1   Total Assets (Millions)  200 non-null    float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 3.3 KB\n",
      "\n",
      "Missing values count:\n",
      " Years of Service           0\n",
      "Total Assets (Millions)    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df2.info()\n",
    "null_count = df2.isnull().sum()\n",
    "print(\"\\nMissing values count:\\n\",null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1538c157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ProductID    50 non-null     object\n",
      " 1   ProductName  50 non-null     object\n",
      " 2   Category     50 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.3+ KB\n",
      "\n",
      "Missing Values:\n",
      " ProductID      0\n",
      "ProductName    0\n",
      "Category       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df3.info()\n",
    "null_count2 = df3.isnull().sum()\n",
    "print(\"\\nMissing Values:\\n\", null_count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09149d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   OrderID     1000 non-null   object \n",
      " 1   CustomerID  1000 non-null   object \n",
      " 2   ProductID   1000 non-null   object \n",
      " 3   Quantity    1000 non-null   int64  \n",
      " 4   Price       1000 non-null   float64\n",
      " 5   OrderDate   1000 non-null   object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 47.0+ KB\n",
      "\n",
      "Missing Values:\n",
      " OrderID       0\n",
      "CustomerID    0\n",
      "ProductID     0\n",
      "Quantity      0\n",
      "Price         0\n",
      "OrderDate     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df4.info()\n",
    "null_count3 = df4.isnull().sum()\n",
    "print(\"\\nMissing Values:\\n\", null_count3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bfa1028",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    OrderID CustomerID ProductID  Quantity   Price           OrderDate\n",
      "0    O00001      C0066     P0042        13  194.30 2021-01-12 15:57:26\n",
      "1    O00002      C0058     P0050        14  253.92 2022-05-04 06:23:35\n",
      "2    O00003      C0028     P0027        12   49.93 2020-02-17 23:00:30\n",
      "3    O00004      C0078     P0022        14  102.03 2020-02-24 03:50:25\n",
      "4    O00005      C0003     P0001         5  182.74 2022-04-16 15:35:10\n",
      "..      ...        ...       ...       ...     ...                 ...\n",
      "995  O00996      C0027     P0016        14  212.62 2020-02-18 06:40:25\n",
      "996  O00997      C0056     P0038        18  147.44 2021-12-06 08:46:33\n",
      "997  O00998      C0045     P0014        12  223.43 2023-07-09 21:57:03\n",
      "998  O00999      C0093     P0041        16   72.84 2021-03-14 02:27:11\n",
      "999  O01000      C0099     P0044        19  357.92 2020-01-09 03:37:08\n",
      "\n",
      "[1000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df4['OrderDate']=pd.to_datetime(df4['OrderDate'], errors= 'coerce')\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fac5a1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   OrderID     1000 non-null   object        \n",
      " 1   CustomerID  1000 non-null   object        \n",
      " 2   ProductID   1000 non-null   object        \n",
      " 3   Quantity    1000 non-null   int64         \n",
      " 4   Price       1000 non-null   float64       \n",
      " 5   OrderDate   1000 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(3)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c210eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicate=df2.duplicated().sum()\n",
    "print(duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee2c1b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicate_2 = df3.duplicated().sum()\n",
    "print(duplicate_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49f2f171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicate_3 = df4.duplicated().sum()\n",
    "print(duplicate_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc94dcd",
   "metadata": {},
   "source": [
    "__Task2: Sub-setting and Filtering__\n",
    "1. Subset the ”sales data” Data-frame to include only orders placed in the last year.\n",
    "2. Subset the ”customer data” Data-frame to include only customers who have made a purchase\n",
    "within last year.\n",
    "3. Filter the ”product data” to include only products that belong to specified category(e.g.”Electronics”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf6bf372-2311-469a-b521-5e61c6a62cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductID ProductName Category\n",
      "3      P0004   Product_4     Home\n",
      "11     P0012  Product_12     Home\n",
      "14     P0015  Product_15     Home\n",
      "18     P0019  Product_19     Home\n",
      "22     P0023  Product_23     Home\n",
      "27     P0028  Product_28     Home\n",
      "32     P0033  Product_33     Home\n",
      "36     P0037  Product_37     Home\n",
      "37     P0038  Product_38     Home\n",
      "38     P0039  Product_39     Home\n",
      "44     P0045  Product_45     Home\n",
      "48     P0049  Product_49     Home\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrderID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price</th>\n",
       "      <th>OrderDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>O00013</td>\n",
       "      <td>C0039</td>\n",
       "      <td>P0024</td>\n",
       "      <td>12</td>\n",
       "      <td>167.86</td>\n",
       "      <td>2023-11-19 11:09:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>O00018</td>\n",
       "      <td>C0063</td>\n",
       "      <td>P0010</td>\n",
       "      <td>12</td>\n",
       "      <td>472.58</td>\n",
       "      <td>2023-08-04 01:39:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>O00037</td>\n",
       "      <td>C0087</td>\n",
       "      <td>P0001</td>\n",
       "      <td>6</td>\n",
       "      <td>21.25</td>\n",
       "      <td>2023-11-21 23:39:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>O00048</td>\n",
       "      <td>C0051</td>\n",
       "      <td>P0047</td>\n",
       "      <td>4</td>\n",
       "      <td>313.91</td>\n",
       "      <td>2023-10-25 20:11:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>O00051</td>\n",
       "      <td>C0072</td>\n",
       "      <td>P0006</td>\n",
       "      <td>9</td>\n",
       "      <td>382.32</td>\n",
       "      <td>2023-10-20 04:42:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OrderID CustomerID ProductID  Quantity   Price           OrderDate\n",
       "12  O00013      C0039     P0024        12  167.86 2023-11-19 11:09:52\n",
       "17  O00018      C0063     P0010        12  472.58 2023-08-04 01:39:02\n",
       "36  O00037      C0087     P0001         6   21.25 2023-11-21 23:39:48\n",
       "47  O00048      C0051     P0047         4  313.91 2023-10-25 20:11:53\n",
       "50  O00051      C0072     P0006         9  382.32 2023-10-20 04:42:53"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_date = pd.Timestamp.now()\n",
    "\n",
    "one_year_ago = current_date - pd.DateOffset(years=1)\n",
    "recent_sales_data = df4[df4['OrderDate'] >= one_year_ago]\n",
    "\n",
    "electronics_products = df3[df3['Category'] == 'Home']\n",
    "print(electronics_products)\n",
    "recent_sales_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b456b60-4367-494e-b06f-29c472e8ae80",
   "metadata": {},
   "source": [
    "__Task3: Group Analysis__\r\n",
    "1. Calculate the total revenue for each region.(Revenue = Quantity*Price)\r\n",
    "2. Determine the average and median order value per customer.\r\n",
    "3. Find the top 5 customers in terms of the number of orders placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec457b16-8544-461c-8961-8d73332fc37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID   Revenue  AverageOrderValue  MedianOrderValue\n",
      "0       C0001  17763.33        2220.416250          1965.875\n",
      "1       C0002  20997.90        2099.790000          1820.430\n",
      "2       C0003  17262.93        1150.862000           896.060\n",
      "3       C0004  33580.19        3052.744545          2256.840\n",
      "4       C0005  19044.53        1731.320909           902.100\n",
      "..        ...       ...                ...               ...\n",
      "95      C0096  24590.00        1891.538462           989.650\n",
      "96      C0097  31261.67        3473.518889          3779.610\n",
      "97      C0098  15983.86        2283.408571          2183.160\n",
      "98      C0099  27673.30        2767.330000          2236.000\n",
      "99      C0100   4399.50         879.900000           701.290\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>NumberOfOrders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0093</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0083</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0042</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0078</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0006</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CustomerID  NumberOfOrders\n",
       "0      C0093              19\n",
       "1      C0083              17\n",
       "2      C0042              17\n",
       "3      C0078              16\n",
       "4      C0006              16"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4['Revenue'] = df4['Quantity'] * df4['Price']\n",
    "\n",
    "total_revenue_per_customer = df4.groupby('CustomerID')['Revenue'].sum().reset_index()\n",
    "\n",
    "average_order_value_per_customer = df4.groupby('CustomerID')['Revenue'].mean().reset_index()\n",
    "average_order_value_per_customer.rename(columns={'Revenue': 'AverageOrderValue'}, inplace=True)\n",
    "\n",
    "median_order_value_per_customer = df4.groupby('CustomerID')['Revenue'].median().reset_index()\n",
    "median_order_value_per_customer.rename(columns={'Revenue': 'MedianOrderValue'}, inplace=True)\n",
    "\n",
    "top_5_customers = df4['CustomerID'].value_counts().head(5).reset_index()\n",
    "top_5_customers.columns = ['CustomerID', 'NumberOfOrders']\n",
    "\n",
    "customer_stats = total_revenue_per_customer.merge(average_order_value_per_customer, on='CustomerID') \\\n",
    "                                           .merge(median_order_value_per_customer, on='CustomerID')\n",
    "\n",
    "print(customer_stats)\n",
    "top_5_customers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a062e764-d01c-4ecd-895d-1c006165e02b",
   "metadata": {},
   "source": [
    "__Task4: Merging and Aggregation__\r\n",
    "1. Merge the ”sales data” with ”customer data” on ”CustomerID”.\r\n",
    "2. Merge the resulting Data-frame with ”product data” on ”ProductID”\r\n",
    "3. Calculate the total revenue per product category.\r\n",
    "4. Determine the average revenue per order for each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79ae0984-70b4-490e-86fa-c384bd816698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    OrderID CustomerID ProductID  Quantity   Price           OrderDate  \\\n",
      "0    O00001      C0066     P0042        13  194.30 2021-01-12 15:57:26   \n",
      "1    O00125      C0066     P0025        18  157.08 2023-03-30 08:17:09   \n",
      "2    O00353      C0066     P0017        15  227.91 2020-01-18 07:53:15   \n",
      "3    O00363      C0066     P0034        16  346.22 2023-10-05 18:39:33   \n",
      "4    O00457      C0066     P0004        10  450.60 2020-12-20 01:30:49   \n",
      "..      ...        ...       ...       ...     ...                 ...   \n",
      "995  O00913      C0098     P0011        12  324.19 2023-10-28 09:42:32   \n",
      "996  O00948      C0098     P0003        17  268.73 2020-01-17 02:33:16   \n",
      "997  O00971      C0098     P0032         6  363.86 2022-04-09 16:14:07   \n",
      "998  O00682      C0015     P0034         9  275.78 2022-10-14 14:54:28   \n",
      "999  O00850      C0015     P0037        12  288.80 2021-10-17 14:21:35   \n",
      "\n",
      "     Revenue_sales  AverageOrderValue  MedianOrderValue  \n",
      "0          2525.90        4086.134545           4235.70  \n",
      "1          2827.44        4086.134545           4235.70  \n",
      "2          3418.65        4086.134545           4235.70  \n",
      "3          5539.52        4086.134545           4235.70  \n",
      "4          4506.00        4086.134545           4235.70  \n",
      "..             ...                ...               ...  \n",
      "995        3890.28        2283.408571           2183.16  \n",
      "996        4568.41        2283.408571           2183.16  \n",
      "997        2183.16        2283.408571           2183.16  \n",
      "998        2482.02        2973.810000           2973.81  \n",
      "999        3465.60        2973.810000           2973.81  \n",
      "\n",
      "[1000 rows x 9 columns]\n",
      "    OrderID CustomerID ProductID  Quantity   Price           OrderDate  \\\n",
      "0    O00001      C0066     P0042        13  194.30 2021-01-12 15:57:26   \n",
      "1    O00830      C0063     P0042        14   36.30 2022-07-04 22:32:12   \n",
      "2    O00686      C0035     P0042        19   91.00 2020-10-21 20:04:09   \n",
      "3    O00947      C0006     P0042         5  365.16 2023-08-22 03:46:54   \n",
      "4    O00960      C0062     P0042        10  469.77 2022-08-14 12:16:17   \n",
      "..      ...        ...       ...       ...     ...                 ...   \n",
      "995  O00247      C0014     P0036        13  382.80 2021-10-30 05:44:32   \n",
      "996  O00815      C0067     P0036         8   46.85 2021-06-06 20:20:42   \n",
      "997  O00201      C0017     P0036        11   47.49 2023-03-23 22:43:12   \n",
      "998  O00893      C0083     P0036        17  329.22 2023-08-22 00:50:16   \n",
      "999  O00415      C0048     P0036        17   64.16 2022-10-01 10:14:41   \n",
      "\n",
      "     Revenue_sales  AverageOrderValue  MedianOrderValue ProductName  \\\n",
      "0          2525.90        4086.134545          4235.700  Product_42   \n",
      "1           508.20        2464.737143           959.100  Product_42   \n",
      "2          1729.00        1436.260000           854.820  Product_42   \n",
      "3          1825.80        2807.065000          1525.440  Product_42   \n",
      "4          4697.70        2185.415000          1605.870  Product_42   \n",
      "..             ...                ...               ...         ...   \n",
      "995        4976.40        3020.650000          2409.820  Product_36   \n",
      "996         374.80        1514.091250           960.710  Product_36   \n",
      "997         522.39        2343.300000          1497.025  Product_36   \n",
      "998        5596.74        2740.010588          2879.920  Product_36   \n",
      "999        1090.72        2180.636000          1090.720  Product_36   \n",
      "\n",
      "       Category  \n",
      "0    Technology  \n",
      "1    Technology  \n",
      "2    Technology  \n",
      "3    Technology  \n",
      "4    Technology  \n",
      "..          ...  \n",
      "995        Toys  \n",
      "996        Toys  \n",
      "997        Toys  \n",
      "998        Toys  \n",
      "999        Toys  \n",
      "\n",
      "[1000 rows x 11 columns]\n",
      "     Category  Revenue_sales\n",
      "0       Books      322489.39\n",
      "1     Clothes      352040.42\n",
      "2     Grocery      312957.87\n",
      "3        Home      552333.82\n",
      "4  Technology      312592.77\n",
      "5        Toys      559393.81\n"
     ]
    }
   ],
   "source": [
    "df4['Revenue'] = df4['Quantity'] * df4['Price']\n",
    "\n",
    "merged_sales_customers = df4.merge(customer_stats, on='CustomerID', suffixes=('_sales', '_customer'))\n",
    "\n",
    "merged_sales_customers.drop(columns=['Revenue_customer'], inplace=True)\n",
    "print(merged_sales_customers)\n",
    "\n",
    "merged_data = merged_sales_customers.merge(df3, on='ProductID')\n",
    "print(merged_data)\n",
    "\n",
    "total_revenue_per_category = merged_data.groupby('Category')['Revenue_sales'].sum().reset_index()\n",
    "total_revenue_per_category.rename(columns={'Revenue': 'TotalRevenue'}, inplace=True)\n",
    "print(total_revenue_per_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6858b99-b606-4bdb-8536-b4f94279f7b6",
   "metadata": {},
   "source": [
    "__Task5: Advanced Analysis__\r\n",
    "1. Identify trends in sales over time (e.g., monthly revenue).\r\n",
    "2. Determine the churn rate (percentage of customers who did not make a purchase in the last year).\r\n",
    "3. Perform cohort analysis to understand the customer retention (e.g. grouping customers by the\r\n",
    "month they made their first purchase analyzing their purchasing behavior overtime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "097a773c-c501-40c4-9a51-b59cb6d99b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   YearMonth   Revenue\n",
      "0    2020-01  45925.90\n",
      "1    2020-02  38552.93\n",
      "2    2020-03  68602.02\n",
      "3    2020-04  47854.90\n",
      "4    2020-05  38438.79\n",
      "5    2020-06  54619.50\n",
      "6    2020-07  35290.61\n",
      "7    2020-08  55285.86\n",
      "8    2020-09  45095.04\n",
      "9    2020-10  43660.12\n",
      "10   2020-11  38288.16\n",
      "11   2020-12  48369.69\n",
      "12   2021-01  39541.12\n",
      "13   2021-02  66852.06\n",
      "14   2021-03  51071.48\n",
      "15   2021-04  62226.90\n",
      "16   2021-05  52441.83\n",
      "17   2021-06  55169.93\n",
      "18   2021-07  43938.26\n",
      "19   2021-08  73726.95\n",
      "20   2021-09  27646.51\n",
      "21   2021-10  36084.77\n",
      "22   2021-11  67307.57\n",
      "23   2021-12  35617.36\n",
      "24   2022-01  49780.18\n",
      "25   2022-02  34364.33\n",
      "26   2022-03  73336.70\n",
      "27   2022-04  49562.01\n",
      "28   2022-05  40173.91\n",
      "29   2022-06  28130.50\n",
      "30   2022-07  56410.26\n",
      "31   2022-08  88955.53\n",
      "32   2022-09  60157.85\n",
      "33   2022-10  50447.87\n",
      "34   2022-11  52425.72\n",
      "35   2022-12  47109.01\n",
      "36   2023-01  63495.05\n",
      "37   2023-02  44608.67\n",
      "38   2023-03  75029.43\n",
      "39   2023-04  49077.91\n",
      "40   2023-05  36053.71\n",
      "41   2023-06  61809.77\n",
      "42   2023-07  29570.86\n",
      "43   2023-08  59791.15\n",
      "44   2023-09  54851.94\n",
      "45   2023-10  46966.50\n",
      "46   2023-11  33601.69\n",
      "47   2023-12  54489.27 \n",
      "\n",
      " The churn rate is:  35.0 \n",
      " \n",
      " CohortIndex   0         1         2         3         4         5         6   \\\n",
      "CohortMonth                                                                    \n",
      "2020-01      1.0  0.250000  0.250000  0.300000  0.100000  0.300000  0.150000   \n",
      "2020-02      1.0  0.200000  0.200000  0.066667  0.133333  0.200000  0.200000   \n",
      "2020-03      1.0       NaN  0.142857  0.500000  0.142857  0.071429  0.214286   \n",
      "2020-04      1.0  0.272727       NaN  0.272727  0.090909  0.090909  0.272727   \n",
      "2020-05      1.0  0.250000  0.416667  0.250000       NaN  0.416667  0.166667   \n",
      "2020-06      1.0  0.250000       NaN  0.250000  0.250000       NaN  0.250000   \n",
      "2020-07      1.0       NaN       NaN  0.333333       NaN       NaN       NaN   \n",
      "2020-08      1.0       NaN       NaN  0.333333       NaN       NaN  0.333333   \n",
      "2020-09      1.0  0.428571  0.142857       NaN       NaN  0.428571  0.428571   \n",
      "2020-10      1.0       NaN       NaN       NaN       NaN  0.500000  0.500000   \n",
      "2020-12      1.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "2021-02      1.0  1.000000       NaN       NaN       NaN       NaN  1.000000   \n",
      "2021-03      1.0       NaN       NaN  0.500000  0.500000  0.500000       NaN   \n",
      "2021-06      1.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "2021-10      1.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "2021-11      1.0       NaN  0.500000       NaN       NaN       NaN       NaN   \n",
      "2021-12      1.0  1.000000  1.000000       NaN  1.000000       NaN       NaN   \n",
      "\n",
      "CohortIndex        7         8         9   ...        38        39        40  \\\n",
      "CohortMonth                                ...                                 \n",
      "2020-01      0.300000  0.250000  0.150000  ...  0.350000  0.100000  0.150000   \n",
      "2020-02      0.266667  0.200000  0.266667  ...  0.333333  0.133333  0.133333   \n",
      "2020-03           NaN  0.142857  0.142857  ...  0.142857  0.214286  0.071429   \n",
      "2020-04           NaN  0.181818  0.090909  ...  0.363636       NaN  0.181818   \n",
      "2020-05      0.083333  0.250000  0.250000  ...  0.083333  0.250000  0.250000   \n",
      "2020-06      0.250000       NaN  0.250000  ...  0.500000  0.250000       NaN   \n",
      "2020-07      0.333333  0.333333  0.333333  ...  0.333333       NaN       NaN   \n",
      "2020-08      0.333333  0.333333  0.333333  ...       NaN  0.333333       NaN   \n",
      "2020-09      0.285714  0.142857  0.142857  ...  0.428571  0.285714       NaN   \n",
      "2020-10      0.500000  0.500000       NaN  ...       NaN       NaN       NaN   \n",
      "2020-12           NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "2021-02           NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "2021-03           NaN       NaN  0.500000  ...       NaN       NaN       NaN   \n",
      "2021-06           NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "2021-10           NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "2021-11           NaN  0.500000       NaN  ...       NaN       NaN       NaN   \n",
      "2021-12           NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "\n",
      "CohortIndex        41        42        43        44        45        46    47  \n",
      "CohortMonth                                                                    \n",
      "2020-01      0.150000  0.150000  0.100000  0.050000  0.200000  0.100000  0.15  \n",
      "2020-02      0.200000  0.400000  0.066667  0.200000  0.133333  0.333333   NaN  \n",
      "2020-03      0.214286  0.142857       NaN       NaN  0.142857       NaN   NaN  \n",
      "2020-04      0.363636  0.181818  0.272727  0.363636       NaN       NaN   NaN  \n",
      "2020-05      0.250000  0.083333  0.083333       NaN       NaN       NaN   NaN  \n",
      "2020-06      0.250000  0.250000       NaN       NaN       NaN       NaN   NaN  \n",
      "2020-07      0.333333       NaN       NaN       NaN       NaN       NaN   NaN  \n",
      "2020-08           NaN       NaN       NaN       NaN       NaN       NaN   NaN  \n",
      "2020-09           NaN       NaN       NaN       NaN       NaN       NaN   NaN  \n",
      "2020-10           NaN       NaN       NaN       NaN       NaN       NaN   NaN  \n",
      "2020-12           NaN       NaN       NaN       NaN       NaN       NaN   NaN  \n",
      "2021-02           NaN       NaN       NaN       NaN       NaN       NaN   NaN  \n",
      "2021-03           NaN       NaN       NaN       NaN       NaN       NaN   NaN  \n",
      "2021-06           NaN       NaN       NaN       NaN       NaN       NaN   NaN  \n",
      "2021-10           NaN       NaN       NaN       NaN       NaN       NaN   NaN  \n",
      "2021-11           NaN       NaN       NaN       NaN       NaN       NaN   NaN  \n",
      "2021-12           NaN       NaN       NaN       NaN       NaN       NaN   NaN  \n",
      "\n",
      "[17 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "from operator import attrgetter\n",
    "\n",
    "df4['YearMonth'] = df4['OrderDate'].dt.to_period('M')\n",
    "monthly_revenue = df4.groupby('YearMonth')['Revenue'].sum().reset_index()\n",
    "monthly_revenue['YearMonth'] = monthly_revenue['YearMonth'].astype(str)\n",
    "\n",
    "\n",
    "one_year_ago = pd.to_datetime('today') - pd.DateOffset(years=1)\n",
    "recent_customers = df4[df4['OrderDate'] > one_year_ago]['CustomerID'].unique()\n",
    "total_customers = df4['CustomerID'].unique()\n",
    "churn_rate = (len(total_customers) - len(recent_customers)) / len(total_customers) * 100\n",
    "\n",
    "df4['FirstPurchaseDate'] = df4.groupby('CustomerID')['OrderDate'].transform('min')\n",
    "df4['CohortMonth'] = df4['FirstPurchaseDate'].dt.to_period('M')\n",
    "\n",
    "df4['OrderPeriod'] = df4['OrderDate'].dt.to_period('M')\n",
    "df4['CohortIndex'] = (df4['OrderPeriod'] - df4['CohortMonth']).apply(attrgetter('n'))\n",
    "\n",
    "cohort_data = df4.groupby(['CohortMonth', 'CohortIndex']).agg({'CustomerID': 'nunique'}).reset_index()\n",
    "\n",
    "cohort_pivot = cohort_data.pivot_table(index='CohortMonth', columns='CohortIndex', values='CustomerID')\n",
    "\n",
    "cohort_size = cohort_pivot.iloc[:, 0]\n",
    "retention_matrix = cohort_pivot.divide(cohort_size, axis=0)\n",
    "\n",
    "print(monthly_revenue,\"\\n\\n The churn rate is: \", churn_rate, \"\\n \\n\", retention_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
